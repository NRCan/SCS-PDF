{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d6929ff",
   "metadata": {},
   "source": [
    "# Search-Convert-Select (SCS): A pipeline to locate all the pdf document containing desired information  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda4963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Repos an commands to install required libraries:\n",
    "# Tesseract: https://github.com/madmaze/pytesseract\n",
    "#         https://github.com/tesseract-ocr/tesseract\n",
    "            \n",
    "# pip install PyPDF2\n",
    "# pip install pdfminer\n",
    "\n",
    "import PyPDF2\n",
    "from PyPDF2 import PdfFileMerger\n",
    "import fitz\n",
    "import pdfminer\n",
    "import shutil\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import pytesseract\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa02698",
   "metadata": {},
   "source": [
    "# User inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ef222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The root directory where all the folders will be created\n",
    "root_Dir = r\"C:\\Users\\aamini\\Work\\NRCan\\Automatic data capture\\Analysis\\Phase_1_pdf_search_and_select\" \n",
    "# The location of raw input data inside the root directory\n",
    "raw_data_Dir = r\"C:\\Users\\aamini\\Work\\NRCan\\Automatic data capture\\Analysis\\Phase_1_pdf_search_and_select\\data\" \n",
    "# The path to tessdata directory\n",
    "tessdata_dir_config = r'--tessdata-dir \"C:/Program Files/Tesseract-OCR/tessdata\"'\n",
    "\n",
    "# keywords and criteria parameter for the search function\n",
    "keyword = ['Final Environmental Impact Statement']#,'azimuth', 'inclination','drillhole','depth', 'borehole','overburden', 'ovb']\n",
    "c = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228953a3",
   "metadata": {},
   "source": [
    "### Let's create the necessary folders and setup their paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c483fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def directories (root_Dir):\n",
    "    pathlib.Path(root_Dir+ '/' + 'Image_pdf_Dir').mkdir(exist_ok=True) \n",
    "    pathlib.Path(root_Dir+ '/' + 'Text_pdf_Dir').mkdir(exist_ok=True)\n",
    "    pathlib.Path(root_Dir+ '/' + 'Temp_image_Dir').mkdir(exist_ok=True)\n",
    "    pathlib.Path(root_Dir+ '/' + 'Temp_pdf_Dir').mkdir(exist_ok=True)\n",
    "    pathlib.Path(root_Dir+ '/' + 'Converted_Dir').mkdir(exist_ok=True)\n",
    "    pathlib.Path(root_Dir+ '/' + 'Output_Dir').mkdir(exist_ok=True)\n",
    "\n",
    "    \n",
    "directories(root_Dir)\n",
    "\n",
    "Output_Dir = root_Dir+ '/' + 'Output_Dir'\n",
    "Temp_image_Dir = root_Dir+ '/' + 'Temp_image_Dir'\n",
    "Temp_pdf_Dir = root_Dir+ '/' + 'Temp_pdf_Dir'\n",
    "Converted_Dir = root_Dir+ '/' + 'Converted_Dir'\n",
    "Image_pdf_Dir = root_Dir+ '/' + 'Image_pdf_Dir'\n",
    "Text_pdf_Dir = root_Dir+ '/' + 'Text_pdf_Dir'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d691438e",
   "metadata": {},
   "source": [
    "# 1- Search:\n",
    "\n",
    "## This function gives a summary of pdf file types and separates them into two groups of:\n",
    "####    - pdfs with searchable text (Text_pdf_Dir)\n",
    "####    - pdfs without searchable text (Image_pdf_Dir)\n",
    "\n",
    "### Input: Directory of raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "667b7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function gives a summary of pdf file types (selecteable text or not) for input directory and separates them into two folders\n",
    "def Separate_pdf_type(raw_data_Dir):\n",
    "    Total_pdf = 0\n",
    "    count_mix = 0\n",
    "    count_text = 0\n",
    "    count_image = 0\n",
    "    count_unvalid = 0\n",
    "    for root, dirs, files in os.walk(raw_data_Dir, topdown=False):\n",
    "        for name in dirs:\n",
    "            directory = (root+ '/' +name+ '/')\n",
    "            for filename in os.listdir(directory):\n",
    "                #print (filename)\n",
    "                if filename.endswith(\".pdf\"):\n",
    "                    \n",
    "                    from pdfminer.pdfpage import PDFPage\n",
    "                    #searchable_pages = []\n",
    "                    #non_searchable_pages = []\n",
    "                    #page_num = 0\n",
    "\n",
    "                    with open(directory+filename, 'rb') as infile:\n",
    "                        Total_pdf += 1\n",
    "                        searchable_pages = []\n",
    "                        non_searchable_pages = []\n",
    "                        page_num = 0\n",
    "                        for page in PDFPage.get_pages(infile):\n",
    "                            page_num += 1\n",
    "                            if 'Font' in page.resources.keys():\n",
    "                                searchable_pages.append(page_num)\n",
    "                            else:\n",
    "                                non_searchable_pages.append(page_num)\n",
    "                    if page_num > 0:\n",
    "                        if len(searchable_pages) == 0:\n",
    "                            count_image += 1\n",
    "                            shutil.copy(os.path.join(directory, filename), Image_pdf_Dir)\n",
    "                            #print(f\"Document '{fname}' has {page_num} page(s). \"\n",
    "                            #      f\"Complete document is non-searchable\")\n",
    "                        elif len(non_searchable_pages) == 0:\n",
    "                            count_text += 1\n",
    "                            shutil.copy(os.path.join(directory, filename), Text_pdf_Dir)\n",
    "                            #print(f\"Document '{fname}' has {page_num} page(s). \"\n",
    "                            #      f\"Complete document is searchable\")\n",
    "                        else:\n",
    "                            count_mix += 1\n",
    "                            shutil.copy(os.path.join(directory, filename), Image_pdf_Dir)\n",
    "                            #print (f\"Mixed Document\")\n",
    "                            #print(f\"searchable_pages : {searchable_pages}\")\n",
    "                            #print(f\"non_searchable_pages : {non_searchable_pages}\")\n",
    "                    else:\n",
    "                        count_unvalid += 1\n",
    "                        #print(f\"Not a valid document\")\n",
    "    print (f\"Total Number of pdfs:\", Total_pdf)\n",
    "    print (f\"Number of pdfs containing only Text:\", count_text)\n",
    "    print (f\"Number of pdfs containing only Image:\", count_image)\n",
    "    print (f\"Number of Mixed Text/Image pdfs:\", count_mix)\n",
    "    print (f\"Number of Unvalid pdfs:\", count_unvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6adab732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PDF <_io.BufferedReader name='C:\\\\Users\\\\aamini\\\\Work\\\\NRCan\\\\Automatic data capture\\\\Analysis\\\\Phase_1_pdf_search_and_select\\\\data\\\\Data\\\\NTGSref_2023February10 (5)\\\\034725_034725\\\\034725_Report\\\\034725_Appendices/034725_Appendix_G_Dril_Core_Assay_Certificates/COA_YW17034549_122387-38289151.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      "The PDF <_io.BufferedReader name='C:\\\\Users\\\\aamini\\\\Work\\\\NRCan\\\\Automatic data capture\\\\Analysis\\\\Phase_1_pdf_search_and_select\\\\data\\\\Data\\\\NTGSref_2023February10 (5)\\\\034725_034725\\\\034725_Report\\\\034725_Appendices/034725_Appendix_G_Dril_Core_Assay_Certificates/COA_YW17039051_122387-38357039.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      "The PDF <_io.BufferedReader name='C:\\\\Users\\\\aamini\\\\Work\\\\NRCan\\\\Automatic data capture\\\\Analysis\\\\Phase_1_pdf_search_and_select\\\\data\\\\Data\\\\NTGSref_2023February10 (5)\\\\034725_034725\\\\034725_Report\\\\034725_Appendices/034725_Appendix_G_Dril_Core_Assay_Certificates/COA_YW17041433_122387-38491986.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      "The PDF <_io.BufferedReader name='C:\\\\Users\\\\aamini\\\\Work\\\\NRCan\\\\Automatic data capture\\\\Analysis\\\\Phase_1_pdf_search_and_select\\\\data\\\\Data\\\\NTGSref_2023February12 (1)\\\\085474_085474\\\\085474_085474_Digital/085474_Volume 2/App III.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of pdfs: 703\n",
      "Number of pdfs containing only Text: 385\n",
      "Number of pdfs containing only Image: 275\n",
      "Number of Mixed Text/Image pdfs: 43\n",
      "Number of Unvalid pdfs: 0\n"
     ]
    }
   ],
   "source": [
    "Separate_pdf_type(raw_data_Dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681ab4d3",
   "metadata": {},
   "source": [
    "# 2- Convert:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9e4822",
   "metadata": {},
   "source": [
    "### This function converts pdfs without sellectable text into pdfs with sellectable text using OCR.\n",
    "\n",
    "### Input: Directory of image pdfs created by previous function (Image_pdf_Dir)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "284a7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function converts image pdfs to image files and then uses OCR to convert them back to pdfs with selectable text.\n",
    "def To_selectable_text_convertor(Image_pdf_Dir):\n",
    "    \n",
    "    mat = fitz.Matrix(200 / 72, 200 / 72)  # sets zoom factor for 200 dpi\n",
    "    \n",
    "    for root, dirs, files in os.walk(Image_pdf_Dir, topdown=False):\n",
    "        for filename in files:\n",
    "#            print(filename)\n",
    "            doc = fitz.open(Image_pdf_Dir +'/' +filename)\n",
    "            for page in doc:  # convert and save all images into temp_image_dir\n",
    "                pix = page.get_pixmap(matrix=mat)\n",
    "                img_filename = \"page-%04i.png\" % page.number\n",
    "                pix.pil_save(Temp_image_Dir +'/' + img_filename, format=\"PNG\", dpi=(200,200))\n",
    "              \n",
    "                \n",
    "            #now let's convert images in temp_image_dir folder to a single pdf file and copy the file into the converted_dir:\n",
    "            # first: converts each image into a separate pdf file\n",
    "            # uses pdffilemerger to merge all pages into a single pdf\n",
    "            # copies the merged pdf into converted folder and deletes all images and pdf in temp folders\n",
    "            # moves all merged pdfs from converted folder into text_pdf_dir\n",
    "                        \n",
    "            for root, dirs, files in os.walk(Temp_image_Dir, topdown=False):\n",
    "                for imagename in files:\n",
    "#                    print(filename)\n",
    "                    pdf = pytesseract.image_to_pdf_or_hocr(Temp_image_Dir + '/' + imagename, extension='pdf', config=tessdata_dir_config)\n",
    "                    with open(Temp_pdf_Dir + '/' +imagename[0:9]+ '.pdf', 'w+b') as f:\n",
    "                        f.write(pdf) # pdf type is bytes by default\n",
    "#                f.close()\n",
    "            \n",
    "            #Create an instance of PdfFileMerger() class\n",
    "            merger = PdfFileMerger()\n",
    "            for root, dirs, files in os.walk(Temp_pdf_Dir, topdown=False):\n",
    "                for pdf_file in files:\n",
    "                    merger.append(Temp_pdf_Dir + '/' + pdf_file)  #Append PDF files\n",
    "                merger.write(Converted_Dir + '/' + filename)   #Write out the merged PDF file\n",
    "                merger.close()\n",
    "\n",
    "            #remove all temp files    \n",
    "            for root, dirs, files in os.walk(Temp_image_Dir):\n",
    "                for file in files:\n",
    "                    os.remove(os.path.join(root, file))\n",
    "            for root, dirs, files in os.walk(Temp_pdf_Dir):\n",
    "                for file in files:\n",
    "                    os.remove(os.path.join(root, file))\n",
    "    # move all merged pdfs to text_pdf_dir    \n",
    "    for root, dirs, files in os.walk(Converted_Dir):\n",
    "        for file in files:\n",
    "            shutil.move(Converted_Dir+'/'+file, Text_pdf_Dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2059b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "To_selectable_text_convertor(Image_pdf_Dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40cb3f3",
   "metadata": {},
   "source": [
    "# 3- Select"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5b5f83",
   "metadata": {},
   "source": [
    "### Finds pfds containing defined keywords and copies them into output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a535466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_pdf_by_keywords(Text_pdf_Dir, keyword, c, Output_Dir):\n",
    "    # Text_pdf_Dir: direcory of all pdf files with selectable text\n",
    "    # Keyword: list of keywords the you want to look for in lowercase\n",
    "    # c (number): criteria on number of keywords for selecting pdf. \n",
    "        # If all keywords are required: c= len(keyword)\n",
    "        # If only one keyword is enough: c=1\n",
    "    # Dest_Dir = output flder for pdf files containing keywords\n",
    "    Total_checked_pdfs = 0\n",
    "    Total_copied_pdfs = 0\n",
    "    \n",
    "    for root, dirs, files in os.walk(Text_pdf_Dir, topdown=False):\n",
    "        for file in files:\n",
    "            doc = fitz.open(Text_pdf_Dir+'/'+file)  # open document\n",
    "            text = \"\"\n",
    "            #print(doc)\n",
    "            Total_checked_pdfs += 1\n",
    "            for page in doc:  # iterate the document pages\n",
    "                counter = 0\n",
    "                text += page.get_text() # get all text in pdf document\n",
    "            for k in keyword:  # search for keywords\n",
    "                if k in text:\n",
    "                    counter += 1\n",
    "                    if counter == c:\n",
    "                        Total_copied_pdfs += 1\n",
    "                        shutil.copy(Text_pdf_Dir +'/'+ file, Output_Dir)\n",
    "                        print(counter)\n",
    "                        print(file)\n",
    "                            \n",
    "## To skip functions 1&2 and search directly in raw data folder comment above lines and uncomment below:\n",
    "# def select_pdf_by_keywords(raw_data_Dir, keyword, c, Output_Dir):\n",
    "#     # Text_pdf_Dir: direcory of all pdf files with selectable text\n",
    "#     # Keyword: list of keywords the you want to look for in lowercase\n",
    "#     # c (number): criteria on number of keywords for selecting pdf. \n",
    "#         # If all keywords are required: c= len(keyword)\n",
    "#         # If only one keyword is enough: c=1\n",
    "#     # Dest_Dir = output flder for pdf files containing keywords\n",
    "#    Total_checked_pdfs = 0\n",
    "#    Total_copied_pdfs = 0\n",
    "    \n",
    "#    for root, dirs, files in os.walk(raw_data_Dir, topdown=False):\n",
    "#         for name in dirs:\n",
    "#             directory = (root+ '/' +name+ '/')\n",
    "#             for filename in os.listdir(directory):\n",
    "#                 print (filename)\n",
    "#                 if filename.endswith(\".pdf\"):\n",
    "#                     doc = fitz.open(directory+filename)  # open document\n",
    "#                     #print(doc)\n",
    "#                     Total_checked_pdfs += 1\n",
    "#                     for page in doc:  # iterate the document pages\n",
    "#                         counter = 0\n",
    "#                         text = \"\"\n",
    "#                         text += page.get_text() # get all text in pdf document\n",
    "#                         for k in keyword:\n",
    "#                             if k in text:\n",
    "#                                 counter += 1\n",
    "#                                 if counter >= c:\n",
    "#                                     Total_copied_pdfs += 1\n",
    "#                                     shutil.copy(os.path.join(directory, filename), Output_Dir)\n",
    "#                                     print(counter)\n",
    "#                                     print(filename)\n",
    "    print('Checked pdf files:', Total_checked_pdfs)\n",
    "    print('copied pdf files:', Total_copied_pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fe477e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "140506-11MN034-Golder Rpt Vol 7-Freshwater Envir-Pt 13-IA2E.pdf\n",
      "Checked pdf files: 1\n",
      "copied pdf files: 1\n"
     ]
    }
   ],
   "source": [
    "select_pdf_by_keywords(Text_pdf_Dir, keyword, c, Output_Dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
